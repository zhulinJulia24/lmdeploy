name: daily_ete_test

on:
  workflow_dispatch:
  schedule:
    - cron:  '00 21 * * *'

env:
  HOST_PIP_CACHE_DIR: /nvme/github-actions/pip-cache
  HOST_LOCALTIME: /usr/share/zoneinfo/Asia/Shanghai
  OUTPUT_FOLDER: cuda11.8_dist_${{ github.run_id }}


jobs:
  linux-build:
    runs-on: ubuntu-latest
    env:
      PYTHON_VERSION: py38
      PLAT_NAME: manylinux2014_x86_64
      DOCKER_TAG: cuda11.8
    steps:
      - name: Free disk space
        uses: jlumbroso/free-disk-space@main
        with:
          # This might remove tools that are actually needed, if set to "true" but frees about 6 GB
          tool-cache: false
          docker-images: false
          # All of these default to true, but feel free to set to "false" if necessary for your workflow
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          swap-storage: false
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Build
        run: |
          echo ${PYTHON_VERSION}
          echo ${PLAT_NAME}
          echo ${DOCKER_TAG}
          echo ${OUTPUT_FOLDER}
          echo ${GITHUB_RUN_ID}
          # remove -it
          sed -i 's/docker run --rm -it/docker run --rm/g' builder/manywheel/build_wheel.sh
          bash builder/manywheel/build_wheel.sh ${PYTHON_VERSION} ${PLAT_NAME} ${DOCKER_TAG} ${OUTPUT_FOLDER}
      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          if-no-files-found: error
          path: builder/manywheel/${{ env.OUTPUT_FOLDER }}
          retention-days: 1
          name: my-artifact-${{ github.run_id }}


  test_functions:
    runs-on: [self-hosted, linux-a100]
    timeout-minutes: 240 # 4hours
    needs: linux-build
    env:
      REPORT_DIR: /nvme/qa_test_models/test-reports
    container:
      image: nvcr.io/nvidia/tritonserver:22.12-py3
      options: "--gpus=all --ipc=host --user root -e PIP_CACHE_DIR=/root/.cache/pip"
      volumes:
        - /nvme/github-actions/pip-cache:/root/.cache/pip
        - /nvme/github-actions/packages:/root/packages
        - /nvme/qa_test_models:/nvme/qa_test_models
        - /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime:ro
    steps:
      - name: Download Artifacts1
        continue-on-error: true
        uses: actions/download-artifact@v4
        with: 
          path: builder/manywheel/${{ env.OUTPUT_FOLDER }}
          name: my-artifact-${{ github.run_id }}
      - name: Download Artifacts2
        uses: actions/download-artifact@v4
        with: 
          path: my-artifact-${{ github.run_id }}
      - name: Download Artifacts3
        uses: actions/download-artifact@v4
        with: 
          name: my-artifact-${{ github.run_id }}
      - name: Clone repository
        uses: actions/checkout@v2
      - name: Install pytorch
        run: |
          python3 -m pip cache dir
          python3 -m pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118
      - name: Install lmdeploy
        run: |
          python3 -m pip install packaging protobuf transformers_stream_generator transformers==4.33.0 datasets==2.14.7
          # manually install flash attn
          # the install packeage from. https://github.com/Dao-AILab/flash-attention/releases/download/v2.3.6/flash_attn-2.3.6+cu118torch2.0cxx11abiFALSE-cp38-cp38-linux_x86_64.whl
          python3 -m pip install /root/packages/flash_attn-2.3.6+cu118torch2.1cxx11abiFALSE-cp38-cp38-linux_x86_64.whl
          python3 -m pip install -r requirements.txt -r requirements/test.txt
          python3 -m pip install builder/manywheel/${{ env.OUTPUT_FOLDER }}/*
      - name: Check env
        run: |
          python3 -m pip list
          lmdeploy check_env
      - name: Test lmdeploy - quantization
        run: |
          pytest autotest -m 'quantization or quantization_w8a8' -n 8 --alluredir=allure-results --clean-alluredir
      - name: Test lmdeploy - convert
        run: |
          pytest autotest -m convert -n 6 --alluredir=allure-results --reruns 2
      - name: Test lmdeploy - pipeline
        continue-on-error: true
        run: pytest autotest -m 'pipeline_chat or pipeline_chat_pytorch' --alluredir=allure-results --reruns 2
      - name: Test lmdeploy - restful
        continue-on-error: true
        run: pytest autotest -m restful_api --alluredir=allure-results --reruns 2
      - name: Test lmdeploy - chat
        continue-on-error: true
        timeout-minutes: 50
        run: |
          pytest autotest -m 'command_chat or command_chat_hf or command_chat_pytorch' -n 4 --alluredir=allure-results --reruns 2
      - name: Test lmdeploy - rerun fail cases
        run:
          pytest autotest --alluredir=allure-results --lf
      - name: Generate reports
        if: always()
        run: |
          export date_today="$(date +'%Y%m%d-%H%M%S')"
          export report_dir="$REPORT_DIR/$date_today"
          echo "Save report to $ALLURE_DIR"
          allure generate -c -o $report_dir
      - name: Clear workfile
        if: always()
        run: |
          export workdir=$(pwd)
          cd ..
          rm -rf $workdir
          mkdir $workdir
          chmod -R 777 $workdir
